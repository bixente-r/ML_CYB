{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# AERO 5 - Hands on Machine Learning for cybersecurity (2023/2024)\n",
    "\n",
    "\n",
    "# 2- Ham or  Spam? \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab session we will discuss how Machine Learning is used for spam detection. We will define our own vectorizer to clear the datasets. Then, we will use logistic regression, single neuron perceptron and the naive bayes classifier to train our model! \n",
    "\n",
    "The `scikit-learn` documentation is complete and should be consulted whenever necessary. In particular herein you can consult:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a binary classification technique. A key difference from linear regression is that the output value being modeled is a binary value rather than a numeric value. In this exercise, we will apply a logistic regression model to ingest SMS spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The considered dataset herein consists of a collection of 425 items from the Grumbletext website which is a site in the UK where users manually report spam text messages. In addition to the spam text messages that were randomly chosen from the National University of Singapore SMS Corpus (NSC) and have also been added to the dataset. Another 450 benign SMS messages where collected from Caroline Tag’s PhD thesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start by importing the relevant packages : the `pandas` will be used to enable data frame capabilities, the `scikit-learn` package will be used to divide the data into training and testing datasets. We will also use the logistic regression available in `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Import the dataset `SMSSpamCollection.csv` and analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For featurization, the TF-IDF method is used. Transform then the data to fit the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Consider the following test dataset : 'URGENT! Your Mobile No 1234 was awarded a Prize', 'Hey honey, what’s up?' to predict the accuracy of the model. Conclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is about using the naive bayes classifier for spam filtering based on the same dataset `SMSSpamCollection.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make sure to split the data into appropriate train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mails provided in data are full of unstructured mess, so it is important to preprocess this text before feature extraction and modelling. Tokenization converts continuous stream of words into separate token for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def get_tokens(msg):\n",
    "    return TextBlob(str(msg)).words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Then the process of lemmatization groups together the inflected forms of a word so they can be analyzed as a single item, identified by the word's lemma, or dictionary form. Hence word like 'moved' and 'moving' will be reduced to 'move. Edit the next cell to write a lemmatization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "def get_lemmas(msg):\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract text features known as TF-IDF features. Then transform the data to fit the multinomial naïve bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the model now to make a prediction on a sample text. Then compute the accuracy of the model.Conclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single neural network classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will see a concrete example of the use of perceptron. The preprocessed dataset `sms_spam_perceptron.csv` is considered where messages containing the buy and sex keywords, count for each message (ham or spam) the number of occurences of the keyword present in the text of messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start by importing the required librairies, loading the dataset, analyzing it and extracting then the features and the target labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Divide the input data between train ans test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define now your perceptron and proceed to estimate the values on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Verify the accuracy of the proposed perceptron model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Despite the relative simplicity to implement the perceptron, it suffers from some limitations. Plot the decision regions between both obtaines classes and decribe the observed limitations. Conclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL\n",
    "from defs import plot_decision_regions\n",
    "# ====================== Your code here =================\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
