{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# AERO 5 - Hands on Machine Learning for cybersecurity (2022/2023)\n",
    "\n",
    "\n",
    "# 3– Machine Learning for email fraud and spam detection\n",
    "\n",
    "by Leila GHARSALLI\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab session we will discuss how the ML is used for spam detection. We will define our own vectorizer to clear the datasets. Then, we will use logistic regression and the naive bayes classifier to train our model! \n",
    "\n",
    "The `scikit-learn` documentation is complete and should be consulted whenever necessary. In particular herein you can consult:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a binary classification technique. A key difference from linear regression is that the output value being modeled is a binary value rather than a numeric value. In this exercise, we will apply a logistic regression model to ingest SMS spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of a collection of 425 items from the Grumbletext website which is a site in the UK where users manually report spam text messages. In addition to the spam text messages that were randomly chosen from the National University of Singapore SMS Corpus (NSC) and have also been added to the dataset. Another 450 benign SMS messages where collected from caroline Tag’s PhD thesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "Start by importing the relevant packages : the `pandas` will be used to enable data frame capabilities, the `scikit-learn` package will be used to divide the data into training and testing datasets. We will also use the logistic regression available in `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "Import the dataset ''SMSSpamCollection.csv'' and analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "For featurization, the TF-IDF method is used. Transform then the data to fit the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4:\n",
    "Consider the following test dataset : 'URGENT! Your Mobile No 1234 was awarded a Prize', 'Hey honey, what’s up?' to predict the accuracy of the model. Conclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is about using the naive bayes classifier for spam filtering. For this purpose, we will consider the dataset ''sms_spam_no_header.csv''."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "Start by importing the relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: \n",
    "Import the dataset ‘SMSSpam_no_header.csv’ and split it into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mails provided in data are full of unstructured mess, so it is important to preprocess this text before feature extraction and modelling. Tokenization converts continuous stream of words into separate token for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def get_tokens(msg):\n",
    "return TextBlob(str(msg)).words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the process of lemmatization groups together the inflected forms of a word so they can be analyzed as a single item, identified by the word's lemma, or dictionary form. Hence word like 'moved' and 'moving' will be reduced to 'move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas(msg):\n",
    "lemmas = []\n",
    "words = get_tokens(msg)\n",
    "for word in words:\n",
    " lemmas.append(word.lemma)\n",
    "return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "Extract text features known as TF-IDF features. Then transform the data to fit the `multinomial naïve bayes` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4:\n",
    "Use the model now to make a prediction on a sample text. Then compute the accuracy of the model.Conclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Naïve Bayes classifier and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the follwing code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_Class=pd.value_counts(data[\"v1\"], sort= True)\n",
    "count_Class.plot(kind= 'bar', color= [\"blue\", \"orange\"])\n",
    "plt.title('Bar chart')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_Class.plot(kind = 'pie',  autopct='%1.0f%%')\n",
    "plt.title('Pie chart')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = Counter(\" \".join(data[data['v1']=='ham'][\"v2\"]).split()).most_common(20)\n",
    "df1 = pd.DataFrame.from_dict(count1)\n",
    "df1 = df1.rename(columns={0: \"words in non-spam\", 1 : \"count\"})\n",
    "count2 = Counter(\" \".join(data[data['v1']=='spam'][\"v2\"]).split()).most_common(20)\n",
    "df2 = pd.DataFrame.from_dict(count2)\n",
    "df2 = df2.rename(columns={0: \"words in spam\", 1 : \"count_\"})\n",
    "\n",
    "df1.plot.bar(legend = False)\n",
    "y_pos = np.arange(len(df1[\"words in non-spam\"]))\n",
    "plt.xticks(y_pos, df1[\"words in non-spam\"])\n",
    "plt.title('More frequent words in non-spam messages')\n",
    "plt.xlabel('words')\n",
    "plt.ylabel('number')\n",
    "plt.show()\n",
    "\n",
    "df2.plot.bar(legend = False, color = 'orange')\n",
    "y_pos = np.arange(len(df2[\"words in spam\"]))\n",
    "plt.xticks(y_pos, df2[\"words in spam\"])\n",
    "plt.title('More frequent words in spam messages')\n",
    "plt.xlabel('words')\n",
    "plt.ylabel('number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = feature_extraction.text.CountVectorizer(stop_words = 'english')\n",
    "X = f.fit_transform(data[\"v2\"])\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"v1\"]=data[\"v1\"].map({'spam':1,'ham':0})\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, data['v1'], test_size=0.33, random_state=42)\n",
    "print([np.shape(X_train), np.shape(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_alpha = np.arange(1/100000, 20, 0.11)\n",
    "score_train = np.zeros(len(list_alpha))\n",
    "score_test = np.zeros(len(list_alpha))\n",
    "recall_test = np.zeros(len(list_alpha))\n",
    "precision_test= np.zeros(len(list_alpha))\n",
    "count = 0\n",
    "for alpha in list_alpha:\n",
    "    bayes = naive_bayes.MultinomialNB(alpha=alpha)\n",
    "    bayes.fit(X_train, y_train)\n",
    "    score_train[count] = bayes.score(X_train, y_train)\n",
    "    score_test[count]= bayes.score(X_test, y_test)\n",
    "    recall_test[count] = metrics.recall_score(y_test, bayes.predict(X_test))\n",
    "    precision_test[count] = metrics.precision_score(y_test, bayes.predict(X_test))\n",
    "    count = count + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.matrix(np.c_[list_alpha, score_train, score_test, recall_test, precision_test])\n",
    "models = pd.DataFrame(data = matrix, columns = \n",
    "             ['alpha', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\n",
    "models.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = models['Test Precision'].idxmax()\n",
    "models.iloc[best_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[models['Test Precision']==1].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = models[models['Test Precision']==1]['Test Accuracy'].idxmax()\n",
    "bayes = naive_bayes.MultinomialNB(alpha=list_alpha[best_index])\n",
    "bayes.fit(X_train, y_train)\n",
    "models.iloc[best_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, bayes.predict(X_test))\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "Run the program and make an interpretation of every obtained result inside each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "Apply the same reasoning using the SVM model with the gaussian kernel then compare its accuracy to that of Naïve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
